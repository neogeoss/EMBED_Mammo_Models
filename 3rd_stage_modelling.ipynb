{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b462c7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 11:19:55.668543: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-02-01 11:19:56.392193: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2023-02-01 11:19:56.433724: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-01 11:19:56.433988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.69GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2023-02-01 11:19:56.434052: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-01 11:19:56.434281: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: \n",
      "pciBusID: 0000:21:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2023-02-01 11:19:56.434338: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-01 11:19:56.434564: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 2 with properties: \n",
      "pciBusID: 0000:4b:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2023-02-01 11:19:56.434582: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-02-01 11:19:56.437416: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2023-02-01 11:19:56.437459: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2023-02-01 11:19:56.438420: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2023-02-01 11:19:56.438625: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2023-02-01 11:19:56.439486: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2023-02-01 11:19:56.440204: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2023-02-01 11:19:56.440314: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-02-01 11:19:56.440394: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-01 11:19:56.440702: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-01 11:19:56.440974: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-01 11:19:56.441240: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-01 11:19:56.441511: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-01 11:19:56.441770: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-01 11:19:56.441986: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0, 1, 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU')]\n",
      "*************************************\n",
      "Found 1404 files belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 11:19:56.475723: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-01 11:19:56.725461: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-01 11:19:56.725713: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.69GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2023-02-01 11:19:56.725752: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-01 11:19:56.725920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: \n",
      "pciBusID: 0000:21:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2023-02-01 11:19:56.725955: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-01 11:19:56.726121: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 2 with properties: \n",
      "pciBusID: 0000:4b:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\n",
      "coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s\n",
      "2023-02-01 11:19:56.726157: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-01 11:19:56.726343: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-01 11:19:56.726528: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-01 11:19:56.726713: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-01 11:19:56.726899: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-01 11:19:56.727084: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-01 11:19:56.727247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0, 1, 2\n",
      "2023-02-01 11:19:56.727284: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2023-02-01 11:19:57.407900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-02-01 11:19:57.407929: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 1 2 \n",
      "2023-02-01 11:19:57.407934: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N N N \n",
      "2023-02-01 11:19:57.407937: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 1:   N N N \n",
      "2023-02-01 11:19:57.407939: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 2:   N N N \n",
      "2023-02-01 11:19:57.408121: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-01 11:19:57.408361: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-01 11:19:57.408571: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-01 11:19:57.408793: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-01 11:19:57.408988: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-01 11:19:57.409176: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-01 11:19:57.409367: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-01 11:19:57.409553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 21024 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6)\n",
      "2023-02-01 11:19:57.409846: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-01 11:19:57.410023: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 22308 MB memory) -> physical GPU (device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:21:00.0, compute capability: 8.6)\n",
      "2023-02-01 11:19:57.410225: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-01 11:19:57.410399: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 22308 MB memory) -> physical GPU (device: 2, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:4b:00.0, compute capability: 8.6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 452 files belonging to 2 classes.\n",
      "Found 471 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "---time taken : 1.9285459518432617 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 11:19:59.835546: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_1\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_STRING\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "2023-02-01 11:19:59.845097: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2023-02-01 11:19:59.864887: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3800000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "INFO:tensorflow:batch_all_reduce: 110 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 110 all-reduces with algorithm = nccl, num_packs = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 11:20:25.039310: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2023-02-01 11:20:25.561531: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8100\n",
      "2023-02-01 11:20:26.254169: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8100\n",
      "2023-02-01 11:20:26.383047: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2023-02-01 11:20:27.041141: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8100\n",
      "2023-02-01 11:20:27.570056: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2023-02-01 11:20:28.355631: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234/234 [==============================] - ETA: 0s - loss: 0.7815 - accuracy: 0.5328 - auc: 0.5452 - precision: 0.5278 - recall: 0.5837"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 11:20:43.443362: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_1\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_STRING\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234/234 [==============================] - 49s 87ms/step - loss: 0.7815 - accuracy: 0.5328 - auc: 0.5452 - precision: 0.5278 - recall: 0.5837 - val_loss: 0.6945 - val_accuracy: 0.4845 - val_auc: 0.6643 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/20\n",
      "234/234 [==============================] - 17s 70ms/step - loss: 0.6202 - accuracy: 0.6467 - auc: 0.7176 - precision: 0.6337 - recall: 0.6881 - val_loss: 0.6509 - val_accuracy: 0.6527 - val_auc: 0.7279 - val_precision: 0.6098 - val_recall: 0.9056\n",
      "Epoch 3/20\n",
      "234/234 [==============================] - 17s 71ms/step - loss: 0.5095 - accuracy: 0.7642 - auc: 0.8316 - precision: 0.7317 - recall: 0.8312 - val_loss: 0.7820 - val_accuracy: 0.5819 - val_auc: 0.7051 - val_precision: 0.5526 - val_recall: 0.9914\n",
      "Epoch 4/20\n",
      "234/234 [==============================] - 17s 71ms/step - loss: 0.4434 - accuracy: 0.7984 - auc: 0.8743 - precision: 0.7549 - recall: 0.8813 - val_loss: 0.7810 - val_accuracy: 0.6504 - val_auc: 0.7442 - val_precision: 0.6682 - val_recall: 0.6395\n",
      "Epoch 5/20\n",
      "234/234 [==============================] - 17s 71ms/step - loss: 0.2953 - accuracy: 0.8689 - auc: 0.9443 - precision: 0.8357 - recall: 0.9170 - val_loss: 0.8530 - val_accuracy: 0.6637 - val_auc: 0.7624 - val_precision: 0.6653 - val_recall: 0.6996\n",
      "Epoch 6/20\n",
      "234/234 [==============================] - 17s 71ms/step - loss: 0.2321 - accuracy: 0.9067 - auc: 0.9666 - precision: 0.8955 - recall: 0.9199 - val_loss: 1.0803 - val_accuracy: 0.6659 - val_auc: 0.7367 - val_precision: 0.7330 - val_recall: 0.5536\n",
      "Epoch 7/20\n",
      "234/234 [==============================] - 17s 71ms/step - loss: 0.2088 - accuracy: 0.9103 - auc: 0.9725 - precision: 0.8952 - recall: 0.9285 - val_loss: 0.8834 - val_accuracy: 0.6704 - val_auc: 0.7499 - val_precision: 0.7039 - val_recall: 0.6223\n",
      "Epoch 8/20\n",
      "234/234 [==============================] - 16s 70ms/step - loss: 0.1580 - accuracy: 0.9459 - auc: 0.9837 - precision: 0.9381 - recall: 0.9542 - val_loss: 1.1209 - val_accuracy: 0.6549 - val_auc: 0.7444 - val_precision: 0.6711 - val_recall: 0.6481\n",
      "Epoch 9/20\n",
      "234/234 [==============================] - 17s 71ms/step - loss: 0.1485 - accuracy: 0.9416 - auc: 0.9862 - precision: 0.9364 - recall: 0.9471 - val_loss: 1.3906 - val_accuracy: 0.6593 - val_auc: 0.7358 - val_precision: 0.7182 - val_recall: 0.5579\n",
      "Epoch 10/20\n",
      "234/234 [==============================] - 17s 71ms/step - loss: 0.1138 - accuracy: 0.9523 - auc: 0.9919 - precision: 0.9438 - recall: 0.9614 - val_loss: 1.2056 - val_accuracy: 0.6482 - val_auc: 0.7435 - val_precision: 0.6832 - val_recall: 0.5923\n",
      "Epoch 11/20\n",
      "234/234 [==============================] - 17s 71ms/step - loss: 0.0863 - accuracy: 0.9715 - auc: 0.9952 - precision: 0.9700 - recall: 0.9728 - val_loss: 1.3453 - val_accuracy: 0.6460 - val_auc: 0.7372 - val_precision: 0.6995 - val_recall: 0.5494\n",
      "---time taken : 218.3147931098938 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 11:23:36.048770: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_1\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_STRING\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 2s 28ms/step - loss: 0.9766 - accuracy: 0.8110 - auc: 0.8545 - precision: 0.8398 - recall: 0.7886\n",
      "Test accuracy : 0.8110403418540955\n",
      "Test AUC : 0.854498565196991\n",
      "Test F1 : 0.8134171946611464\n",
      "Test precision : 0.8398268222808838\n",
      "Test recall : 0.7886179089546204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 11:23:42.931516: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "/home/careinfolab/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model_resnet50_simple800_600/resnet152v2_1/assets\n",
      "tf.Tensor(\n",
      "[[188  39]\n",
      " [ 53 197]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2\" # Choose which GPUs by checking current use with nvidia-smi\n",
    "import tensorflow as tf\n",
    "# import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "## Keras library also provides ResNet101V2 and ResNet50V2. Import them and use it for other experiments. \n",
    "from tensorflow.keras.applications import ResNet152V2\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras import metrics\n",
    "import time\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "\n",
    "# Check CUDA functionality, restart kernel to change GPUs\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"*************************************\")\n",
    "print(gpus)\n",
    "print(\"*************************************\")\n",
    "\n",
    "# Define function to preprocess images as required by ResNet\n",
    "def preprocess(images, labels):\n",
    "    return tf.keras.applications.resnet_v2.preprocess_input(images), labels\n",
    "\n",
    "\n",
    "#setup train, validation, and test folders\n",
    "traindir = './train_800_600_simple_comparison_birad'\n",
    "valdir = './val_800_600_simple_comparison_birad'\n",
    "testdir = './test_800_600_simple_comparison_birad'\n",
    "dirName = '800_600'\n",
    "\n",
    "\n",
    "buffersize = 3\n",
    "#im_dim = 512\n",
    "im_dim_x = 800\n",
    "im_dim_y = 600\n",
    "batchSizeIntInitial = 10 \n",
    "batchSizeInt = 6\n",
    "\n",
    "train = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    traindir, image_size=(im_dim_x, im_dim_y), batch_size=batchSizeInt)\n",
    "val = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    valdir, image_size=(im_dim_x, im_dim_y), batch_size=batchSizeInt)\n",
    "test = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    testdir, image_size=(im_dim_x, im_dim_y), batch_size=batchSizeInt)\n",
    "\n",
    "test_ds = test.map(preprocess)\n",
    "train_ds = train.map(preprocess)\n",
    "val_ds = val.map(preprocess)\n",
    "train_ds = train_ds.prefetch(buffer_size=buffersize)\n",
    "val_ds = val_ds.prefetch(buffer_size=buffersize)\n",
    "\n",
    "\n",
    "## set up hyperparameters, such as epochs, learning rates, cutoffs.\n",
    "epochs = 20\n",
    "lr = 0.004\n",
    "cutoff=0.5\n",
    "start_time = time.time()\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with mirrored_strategy.scope(): # the entire model needs to be compiled within the scope of the distribution strategy\n",
    "    cb1 = EarlyStopping(monitor='val_accuracy', patience=4) # define early stopping callback function\n",
    "    cb2 = ReduceLROnPlateau(monitor='val_accuracy', factor=0.2, patience=2, min_lr=0.00001) # define LR reduction callback function\n",
    "    opt = keras.optimizers.Adam(learning_rate=lr)\n",
    "    metr = [metrics.BinaryAccuracy(name='accuracy', threshold=cutoff), metrics.AUC(name='auc'), metrics.Precision(name='precision'),\n",
    "                metrics.Recall(name='recall')]\n",
    "#                 tfa.metrics.F1Score(name='f1_score')]\n",
    "    ptmodel = ResNet50V2(include_top=False, weights='imagenet', classes=2, input_shape=(im_dim_x, im_dim_y, 3), pooling='avg') # compile resnet152v2 with imagenet weights\n",
    "    ptmodel.trainable = False # freeze layers\n",
    "    ptmodel.layers[-1].trainable == True\n",
    "\n",
    "    # un-freeze the BatchNorm layers\n",
    "    for layer in ptmodel.layers:\n",
    "        if \"BatchNormalization\" in layer.__class__.__name__:\n",
    "            layer.trainable = True\n",
    "\n",
    "    last_output = ptmodel.output\n",
    "    x = tf.keras.layers.Flatten()(last_output)\n",
    "    x = tf.keras.layers.Dense(2048, activation='relu')(x)\n",
    "#     x = tf.keras.layers.Dropout(0.15)(x)\n",
    "    x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "#    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
    "    # # x = tf.keras.layers.Dropout(0.5, seed=34)(x)\n",
    "    # x = tf.keras.layers.Dense(64, activation = 'relu')(x)\n",
    "    x = tf.keras.layers.Dense(1, activation = 'sigmoid')(x)\n",
    "    model = tf.keras.Model(ptmodel.input, x)\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='BinaryCrossentropy',\n",
    "                  metrics=metr)\n",
    "\n",
    "print(\"---time taken : %s seconds ---\" % (time.time() - start_time))\n",
    "# Train model\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=epochs, callbacks=[cb1, cb2])\n",
    "print(\"---time taken : %s seconds ---\" % (time.time() - start_time))\n",
    "# Test model\n",
    "testloss, testaccuracy, testauc, precision, recall = model.evaluate(test_ds)\n",
    "print('Test accuracy :', testaccuracy)\n",
    "print('Test AUC :', testauc)\n",
    "\n",
    "F1 = 2*float(precision)*float(recall)/(float(precision) + float(recall))\n",
    "print('Test F1 :', F1)\n",
    "print('Test precision :', precision)\n",
    "print('Test recall :', recall)\n",
    "\n",
    "# Model path setup. \n",
    "if not os.path.exists(\"saved_model_resnet50_simple\"+dirName):\n",
    "    os.makedirs(\"saved_model_resnet50_simple\"+dirName+'/')\n",
    "    \n",
    "model.save('saved_model_resnet50_simple'+dirName+'/resnet152v2_1')\n",
    "predicted_probs = np.array([])\n",
    "true_classes =  np.array([])\n",
    "IterationChecker = 0\n",
    "for images, labels in test_ds:\n",
    "    if IterationChecker == 0:\n",
    "        predicted_probs = model(images)\n",
    "        true_classes = labels.numpy()\n",
    "\n",
    "    IterationChecker += 1\n",
    "\n",
    "    predicted_probs = np.concatenate([predicted_probs,\n",
    "                       model(images)])\n",
    "    true_classes = np.concatenate([true_classes, labels.numpy()])\n",
    "# Since they are sigmoid outputs, you need to transform them into classes with a threshold, i.e 0.5 here:\n",
    "predicted_classes = [1 * (x[0]>=cutoff) for x in predicted_probs]\n",
    "# confusion matrix etc:\n",
    "conf_matrix = tf.math.confusion_matrix(true_classes, predicted_classes)\n",
    "print(conf_matrix)\n",
    "\n",
    "predicted_probs=np.squeeze(predicted_probs)\n",
    "predicted_classes = np.array(predicted_classes)\n",
    "true_classes=np.squeeze(true_classes)\n",
    "summedResults = np.stack((predicted_probs,predicted_classes,true_classes), axis = 1)\n",
    "##Print out statistics which test files are correctly predicted or not. \n",
    "np.savetxt(\"Resnet50_simple_comp_EMBED.csv\", summedResults, delimiter=',', header=\"predicted_probabilty,predicted_classes,true_classes\", comments=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7313563",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
